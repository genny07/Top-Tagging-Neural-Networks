{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MNIST Example\n",
    "\n",
    "\n",
    "## Started May 28, 2019\n",
    "### Genevieve Hayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = dsets.MNIST(root='./data',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())\n",
    "print(train_dataset.train_labels.size())\n",
    "print(test_dataset.test_data.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters/(len(train_dataset)/batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "100\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LSTM Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        #Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        #Building the LSTM\n",
    "        #batch_first=True causes input/output tensors to be of shape (batch, seq_dim, feature)\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,layer_dim,batch_first=True)\n",
    "        \n",
    "        #Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim,x.size(0),self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        #Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim,x.size(0),self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        #28 time steps\n",
    "        #We need to detach as we are doing truncates backpropagation through time (BPTT)\n",
    "        #If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn,cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        #Index hidden state of last time step\n",
    "        # out.size() --> 100,28,100\n",
    "        # out[:,-1,:] --> 100,100 --> only want hidden states of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        #out.size() --> 100,10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#Instantiate Model Class\n",
    "########################\n",
    "\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#Instantiate Loss Class\n",
    "#######################\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "############################\n",
    "#Instantiate Optimizer Class\n",
    "############################\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "len(list(model.parameters())) \n",
    "#We have 6 groups of parameters comprising weights and biases from: \n",
    "#1. Input to Hidden Layer Affine Func, \n",
    "#2. Hidden Layer to Output Affine Func\n",
    "#3. Hidden Layer to Hidden Lay Affine Func\n",
    "\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.09768049418926239. Accuracy: 96\n",
      "Iteration: 1000. Loss: 0.10646624863147736. Accuracy: 96\n",
      "Iteration: 1500. Loss: 0.030511891469359398. Accuracy: 97\n",
      "Iteration: 2000. Loss: 0.01128401793539524. Accuracy: 97\n",
      "Iteration: 2500. Loss: 0.07197527587413788. Accuracy: 97\n",
      "Iteration: 3000. Loss: 0.01486160233616829. Accuracy: 97\n"
     ]
    }
   ],
   "source": [
    "#number of steps to unroll (28x28 size images)\n",
    "seq_dim = 28\n",
    "\n",
    "iter = 0\n",
    "train_loss = 0\n",
    "test_loss = 0\n",
    "train_corrects = 0\n",
    "test_corrects = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        #Load images as a torch tensor with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "        \n",
    "        #Clear gradients with respect to parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get output/logits\n",
    "        #outputs.size() --> 100,10\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        #Getting gradients with respect to parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Store training loss and corrects\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        train_corrects += loss.item()*images.size(0)\n",
    "        \n",
    "        iter += 1   \n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            #Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            #Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #Resize images\n",
    "                images = images.view(-1,seq_dim,input_dim)\n",
    "                \n",
    "                #Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                #Get predicted from the maximum value\n",
    "                _, predicted = torch.max(outputs.data,1)\n",
    "                \n",
    "                #Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                test_loss += loss.item()*images.size(0)\n",
    "            \n",
    "                #extract TP+TN\n",
    "                test_corrects += torch.sum(predicted == labels.data)\n",
    "                \n",
    "                #Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "                TESTaccuracy = 100*correct/total\n",
    "            \n",
    "            #Print loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter,loss.item(),TESTaccuracy))\n",
    "                \n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(images[1])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax() got an unexpected keyword argument 'axis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-bb748549425e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#plt.subplot(1,2,2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#plot_value_array(i,outputs,test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-bb748549425e>\u001b[0m in \u001b[0;36mplot_image\u001b[0;34m(i, predictions_array, true_label, img)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRdGy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create functions to graph the image along with confidence levels\n",
    "\n",
    "#plot image function plots the image of interest along with prediction and truth labels\n",
    "def plot_image(i,predictions_array, true_label,img):\n",
    "    predictions_array,true_label,img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img, cmap=plt.cm.RdGy)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                            100*np.max(predictions_array),\n",
    "                                            class_names[true_label]),\n",
    "                                            color = color)\n",
    "\n",
    "#plot value function creates a bar graph of the confidence levels, colored according to correctness       \n",
    "def plot_value_array(i,predictions_array,true_label):\n",
    "    predictions_array,true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10),predictions_array, color = \"#777777\")\n",
    "    plt.ylim([0,1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')\n",
    "\n",
    "\n",
    "\n",
    "# plot one of them!\n",
    "i = 4 \n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i,outputs,labels,images)\n",
    "#plt.subplot(1,2,2)\n",
    "#plot_value_array(i,outputs,test_labels)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
